{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "words = pd.read_csv('../Processed/no_phon.csv', na_filter = False)\n",
    "words['phon'] = np.NaN\n",
    "words['method'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import epitran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Catalan',\n",
       " 'Czech',\n",
       " 'Danish',\n",
       " 'Dutch',\n",
       " 'English',\n",
       " 'French',\n",
       " 'German',\n",
       " 'Italian',\n",
       " 'Latvian',\n",
       " 'Modern Greek',\n",
       " 'Ossetic',\n",
       " 'Polish',\n",
       " 'Portuguese',\n",
       " 'Romanian',\n",
       " 'Swedish'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(words['language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('deu-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_words = words[words['language'] == \"German\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_german_words = [epi.transliterate(word) for word in german_words['Form']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'German', 'phon'] = new_german_words\n",
    "words.loc[words['language'] == 'German', 'method'] = 'epitran'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('cat-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalan_words = words[words['language'] == \"Catalan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Catalan', 'phon'] = [epi.transliterate(word) for word in catalan_words['Form']]\n",
    "words.loc[words['language'] == 'Catalan', 'method'] = 'epitran'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('ita-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_words = words[words['language'] == \"Italian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Italian', 'phon'] = [epi.transliterate(word) for word in italian_words['Form']]\n",
    "words.loc[words['language'] == 'Italian', 'method'] = 'epitran'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swedish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('swe-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "swedish_words = words[words['language'] == \"Swedish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Swedish', 'phon'] = [epi.transliterate(word) for word in swedish_words['Form']]\n",
    "words.loc[words['language'] == 'Swedish', 'method'] = 'epitran'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('por-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "portuguese_words = words[words['language'] == \"Portuguese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Portuguese', 'phon'] = [epi.transliterate(word) for word in portuguese_words['Form']]\n",
    "words.loc[words['language'] == 'Portuguese', 'method'] = 'epitran'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('pol-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_words = words[words['language'] == \"Polish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Polish', 'phon'] = [epi.transliterate(word) for word in polish_words['Form']]\n",
    "words.loc[words['language'] == 'Polish', 'method'] = 'epitran'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('nld-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_words = words[words['language'] == \"Dutch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Dutch', 'phon'] = [epi.transliterate(word) for word in dutch_words['Form']]\n",
    "words.loc[words['language'] == 'Dutch', 'method'] = 'epitran'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Romanian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('ron-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "romanian_words = words[words['language'] == \"Romanian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Romanian', 'phon'] = [epi.transliterate(word) for word in romanian_words['Form']]\n",
    "words.loc[words['language'] == 'Romanian', 'method'] = 'epitran'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('fra-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_words = words[words['language'] == \"French\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'French', 'phon'] = [epi.transliterate(word) for word in french_words['Form']]\n",
    "words.loc[words['language'] == 'French', 'method'] = 'epitran'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual G2P\n",
    "## https://github.com/jcsilva/multilingual-g2p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done in Bash, see Multilingual-G2P folder. Done for czech, greek, latvian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word list\n",
    "greek_file = open(\"Multilingual-G2P/greek.egs\", \"w+\")\n",
    "greek_forms = list(words.loc[words['language'] == 'Modern Greek', 'Form'])\n",
    "greek_forms = '\\n'.join(greek_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13320"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greek_file.write(greek_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "greek_words = pd.read_csv('Multilingual-G2P/greek.txt', sep = '\\t', header = None, names = [\"Form\", \"phon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "greek_words = [re.sub('\\(el\\)', '', word) for word in list(greek_words['phon'])]\n",
    "# removes (el) marker\n",
    "greek_words = [re.sub('\\(en\\)','',word) for word in greek_words]\n",
    "# remove spaces\n",
    "greek_words = [re.sub(' ','',word) for word in greek_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Modern Greek', 'phon'] = greek_words\n",
    "words.loc[words['language'] == 'Modern Greek', 'method'] = 'multilingual-g2p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latvian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word list\n",
    "latvian_file = open(\"Multilingual-G2P/latvian.egs\", \"w+\")\n",
    "latvian_forms = list(words.loc[words['language'] == 'Latvian', 'Form'])\n",
    "latvian_forms = '\\n'.join(latvian_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12599"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latvian_file.write(latvian_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "latvian_words = pd.read_csv('Multilingual-G2P/latvian.txt', sep = '\\t', header = None, names = [\"Form\", \"phon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "latvian_words = [re.sub(' ','',word) for word in list(latvian_words['phon'])]\n",
    "words.loc[words['language'] == 'Latvian', 'phon'] = latvian_words\n",
    "words.loc[words['language'] == 'Latvian', 'method'] = 'multilingual-g2p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word list\n",
    "czech_file = open(\"Multilingual-G2P/czech.egs\", \"w+\")\n",
    "czech_forms = list(words.loc[words['language'] == 'Czech', 'Form'])\n",
    "czech_forms = '\\n'.join(czech_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12866"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "czech_file.write(czech_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "czech_words = pd.read_csv('Multilingual-G2P/czech.txt', sep = '\\t', header = None, names = [\"Form\", \"phon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "czech_words = [re.sub(' ','',word) for word in list(czech_words['phon'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Czech', 'phon'] = czech_words\n",
    "words.loc[words['language'] == 'Czech', 'method'] = 'multilingual-g2p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ossetic (Cyrilic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructed from Wikipedia, cyrillic to IPA https://en.wikipedia.org/wiki/Ossetian_language#Writing_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('oss-Cyrl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file oss-Cyrl.csv has to be copied into the \"data/map\" directory of the epitran installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "osseticWords = words[words['language'] == \"Ossetic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'Ossetic', 'phon'] = [epi.transliterate(word) for word in osseticWords['Form']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English transcriptions was obtained through the CMU Pronunciation dict transcribed into IPA available here: https://github.com/menelik3/cmudict-ipa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DataForG2P/CMU.in.IPA.txt\", encoding = \"utf-8\") as f:\n",
    "    cmu = dict([line.replace(\",\", \"\").split() for line in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishWords = words[words['language'] == \"English\"]\n",
    "def get_cmu(word, cmudict):\n",
    "    try:\n",
    "        return cmudict[word]\n",
    "    except:\n",
    "        return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.loc[words['language'] == 'English', 'phon'] = [get_cmu(word, cmu) for word in englishWords['Form']]\n",
    "words.loc[words['language'] == 'English', 'method'] = 'cmu.in.ipa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Danish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danish was obtained through ordnet. See Danish Scraper.ipynb for the code. It was added to the data in R because it's less repeatable and more complicated. The scraped phon is in 'DataForG2P/danishOrthPhon.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save new dataframe with all new phon forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.to_csv('no_phon_with_phon.csv', index = False, index_label = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
